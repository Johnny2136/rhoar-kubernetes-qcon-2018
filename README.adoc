= Reactive Microservices on Kubernetes: Using Red Hat OpenShift Application Runtimes
:conum-guard-java: //
ifndef::icons[:conum-guard-java: // //]
:conum-guard-groovy: //
ifndef::icons[:conum-guard-groovy: // //]
:icons: font
:pdf-page-size: Letter
:source-highlighter: rouge
:rouge-theme: github
:rouge-style: github
:doctype: book
Deven Phillips, Jeremy Davis, Ram Maddali
v1.0, 2018-05-22

<<<
[colophon]
= Reactive Microservices and DevOps Pipelines on Kubernetes

(c) 2018 Red Hat, Inc. - All Rights Reserved

This document is designed by Deven Phillips, Jeremy Davis, and Ram Maddali.

<<<
== Overview
Microservices and Containers have changed the entire landscape of software
development in the last few years. We are now able to decompose our development
work into smaller and more digestible components which are easier to understand
and easier to split amongst developer teams for better parallel workflow.

Just as Linux has pretty much won the hearts and minds of most developers
for the operating system of the cloud, Kubernetes has become the de-facto
standard for orchestrating containers at scale.

In this workshop, you will learn how to leverage Containers and Kubernetes
to build a productive DevOps workflow using Kubernetes (Wrapped by OpenShift)
to build, test, deploy, and validate microservices quickly and reliably.

Some of the tools we will leverage in this workshop are listed below:

* http://vertx.io/[Vert.x] - A toolkit for developing reactive applications on the JVM
* https://kubernetes.io/[Kubernetes] (In the form of OpenShift Container Platform 3.9)
* http://infinispan.org/[Infinispan] A distributed in-memory key/value data store
* http://jgroups.org/[JGroups] In conjunction with Infinispan, a cluster discovery system for Vert.x
* https://jenkins.io/[Jenkins] (For continuous integration and continuous delivery)
* https://www.sonarqube.org/[SonarQube] (For code quality analysis)
* https://www.sonatype.com/nexus-repository-sonatype[Sonatype Nexus] (For an artifact repository)
* https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project[OWASP Zed Attack Proxy] (For security analysis of web applications)
* https://www.owasp.org/index.php/OWASP_Dependency_Check[OWASP Dependency Check]
* http://openjdk.org/[Java] - A modern and high-performance programming language
* http://spockframework.org/spock/docs/1.1/index.html[Spock Framework] A testing and specification framework for Java and Groovy applications
* https://nodejs.org/[Node.js] - A programming language well suited to quickly develop applications
* https://projects.spring.io/spring-boot/[Spring Boot] An alternative to writing applications using JavaEE
* https://hoverfly.readthedocs.io/en/latest/[HoverFly] A service virtualization tool which simplifies testing Microservices

<<<
== What we are going to do during today's workshop

. <<#section-1,▼>> OpenShift and Kubernetes Overview
.. <<#section-1-a,▼>> Placeholder
.. <<#section-1-b,▼>> Placeholder
. <<#section-2,▼>> Load up a complete DevOps environment in Kubernetes using Ansible automation
.. <<#section-2-a,▼>> Download/Install OpenShift Client Tools
.. <<#section-2-b,▼>> Clone The Repositories
.. <<#section-2-c,▼>> Log In To OpenShift
.. <<#section-2-d,▼>> Deploy Using Ansible
.. <<#section-2-e,▼>> Final Configurations
. <<#section-3,▼>> Load our existing application code into this DevOps environment and wire it up to our GitHub repos
. <<#section-4,▼>> Create a Vert.x microservice project to work with these existing services and communicate with each other
.. <<#section-4-a,▼>> Set Up For Testing
.. <<#section-4-b,▼>> Familiarize ourselves with some basic Vert.x concepts
.. <<#section-4-c,▼>> Implement Vert.x Kubernetes Config
.. <<#section-4-d,▼>> Configure Vert.x Clustering With Infinispan/JGroups
.. <<#section-4-e,▼>> Implement clients for the noun and adjective services using OpenAPI specifications
.. <<#section-4-f,▼>> Implement a REST API using OpenAPI 3 specifications and service proxies
.. <<#section-4-g,▼>>Implement a new https://vertx.io/docs/vertx-service-proxy/java/[service proxy]
.. <<#section-4-h,▼>>Implement a reactive Kafka system to stream "liked" insults
.. <<#section-4-i,▼>>Generate JavaScript code to integrate our application into the UI
.. <<#section-4-j,▼>>Implement circuit breakers to prevent poor user experience
.. <<#section-4-k,▼>>Implement some BDD tests for our service
. <<#section-4-b,▼>>Run our application code through the DevOps pipeline and resolve issues QUICKLY!
. <<#section-5-b,▼>>Perform code quality analysis and unit/integration testing using SonarQube and HoverFly
. <<#section-6-b,▼>>Analyze our web application for security vulnerabilities using OWASP Zed Attack Proxy
. <<#section-7-b,▼>>Analyze our the library dependencies of our services to check for vulnerable libraries

<<<
=== [[section-2]] Load A Complete DevOps Environment In Kubernetes

[NOTE]
====
While some of the process we will show here is specific to OpenShift, all of the same sorts of capabilities can
be achieved using https://github.com/kubernetes/helm[Helm] in stock Kubernetes (Without the nice UI)
====

==== [[section-2-a]] Download/Install OpenShift Client Tools
You can always download the latest OpenShift CLI tools from Github https://github.com/openshift/origin/releases[HERE]

. Download the correct release for your platform
. Extract the binary executable from the archive file
. Place the `oc` command somewhere that it can be added to your executable PATH
. Update your PATH to include the location of the `oc` command
.. On *NIX systems, you can update your .<shell>rc files to add the location for `oc`
.. On Windows systems, it is recommended to extract the archive into your *Documents* directory and add that folder to your PATH

==== [[section-2-b]] Clone The Repositories

. Open the `insult-service` repository https://github.com/rhoar-qcon-2018/insult-service[HERE]
. Fork the repository to your own GitHub account
. Open the `rhoar-kubernetes-qcon-2018` repository https://github.com/rhoar-qcon-2018/rhoar-kubernetes-qcon-2018[HERE]
. Fork the repository to your own GitHub account
. In your fork of the `rhoar-kubernetes-qcon-2018` repository, edit the file `.gitmodules` to update the Git URL for the `insult-service` to point to your own fork
+
[source,bash]
[subs="specialcharacters,quotes"]
----
[submodule "ui-service"]
	path = ui-service
	url = git@github.com:rhoar-qcon-2018/ui-service.git
[submodule "noun-service"]
	path = noun-service
	url = git@github.com:rhoar-qcon-2018/noun-service.git
[submodule "adjective-service"]
	path = adjective-service
	url = git@github.com:rhoar-qcon-2018/adjective-service.git
[submodule "insult-service"]
	path = insult-service
	url = git@github.com:YOUR_GITHUB_ACCOUNT_HERE/insult-service.git <1>
[submodule "lab-infrastructure-as-code"]
	path = lab-infrastructure-as-code
	url = git@github.com:rhoar-qcon-2018/lab-infrastructure-as-code.git
----
. From your preferred git client:
.. `git clone --recurse-submodules -j8 git@github.com:**YOUR_GITHUB_ACCOUNT_HERE**/rhoar-kubernetes-qcon-2018`

==== [[section-2-c]] Log In To The OpenShift Cluster

[source, bash]
----
$ oc login -u YOUR_USERNAME -p YOUR_PASSWORD https://console.qcon2018.rhpds.redhat.com/
The server uses a certificate signed by an unknown authority.
You can bypass the certificate check, but any data you send to the server could be intercepted by others.
Use insecure connections? (y/n): y

Login successful.

You have access to the following projects and can switch between them with 'oc project <projectname>':

  * my-project
----

==== [[section-2-d]] Deploy The DevOps environment using Ansible

. Open a terminal which can execute Docker commands
. Change directory to the location where you cloned the repositories
. Change into the `lab-infrastructure-as-code` subdirectory
. Execute the `run` script
.. On Windows, use `run.bat`
.. On *NIX, use `run.sh`
. Wait a few minutes for the environment to finish provisioning

==== [[section-2-e]] Final Configurations

. Log in to the Web Console for the cluster https://console.qcon2018.rhpds.redhat.com/[HERE]
. Open your DevOps Environment labelled as `USERNAME-labs-ci-cd`
. Click on the link for *SonarQube* to open it in a new tab/window
. Log in with `admin/admin`
. Generate a new token when prompted and copy it to your clipboard
. Return to the OpenShift Console, click the link for Jenkins
. Log in with your OpenShift Username/Password
. Click on **Manage Jenkins** and then click on **Configure System**
. Locate section labelled **SonarQube servers** and if there is not already a configured server, add one as shown below:
+
====
Name: sonar

Server URL: http://sonarqube:9000

Server version: 5.3. or higher

Server authentication token: <PASTE TOKEN HERE>

SonarQube account login: <BLANK>

SonarQube account password: <BLANK>
====

<<<
=== [[section-3]]


<<<
=== [[section-4]] Create a new Vert.x project
. Ensure that you have Apache Maven >= 3.3.9
. From the `insult-service` directory, run the following command

.Executing Fabric8 Vert.x Plugin To Start A New Project
[source,bash]
----
$ mvn io.fabric8:vertx-maven-plugin:1.0.13:setup -DvertxVersion=3.5.1
[INFO] Scanning for projects...
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building Maven Stub Project (No POM) 1
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- vertx-maven-plugin:1.0.13:setup (default-cli) @ standalone-pom ---
[INFO] No pom.xml found, creating it in /home/dphillips/Documents/RedHat/Workspace/rhoar-kubernetes-qcon-2018/insult-service
Set the project groupId [io.vertx.example]: com.redhat.qcon
Set the project artifactId [my-vertx-project]: insult-service
Set the project version [1.0-SNAPSHOT]: 1.0.0-SNAPSHOT
Set the vertcile class name [MainVerticle]:
[INFO] Creating verticle MainVerticle
[INFO] Creating directory /home/dphillips/Documents/RedHat/Workspace/rhoar-kubernetes-qcon-2018/insult-service/src/main/java/com/redhat/qcon
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 34.510 s
[INFO] Finished at: 2018-05-21T12:07:46-04:00
[INFO] Final Memory: 9M/166M
[INFO] ------------------------------------------------------------------------
----

This will create a new Maven POM file populated based on the values you entered during the setup.

After the POM file has been created, we will need to add some additional libraries for this microservice:

* vertx-web-api-contract
* vertx-rx-java2
* vertx-service-proxy
* vertx-sockjs-service-proxy
* vertx-config-kubernetes-configmap
* vertx-codegen
* vertx-lang-js

All of these are within the `io.vertx` Maven group ID and covered via the depenency management setup 
from the initialization process, so we can put them in without versions as follows:

.POM Excerpt Showing Provided and Processor Dependencies
[source,xml,subs=attributes+]
----
<dependency>
    <groupId>io.vertx</groupId>
    <artifactId>vertx-web-api-contract</artifactId>
</dependency>
<dependency>
    <groupId>io.vertx</groupId>
    <artifactId>vertx-rx-java2</artifactId>
</dependency>
<dependency>
    <groupId>io.vertx</groupId>
    <artifactId>vertx-service-proxy</artifactId>
</dependency>
<dependency>
    <groupId>io.vertx</groupId>
    <artifactId>vertx-sockjs-service-proxy</artifactId>
</dependency>
<dependency>
    <groupId>io.vertx</groupId>
    <artifactId>vertx-config-kubernetes-configmap</artifactId>
</dependency>
<dependency>
    <groupId>io.vertx</groupId>
    <artifactId>vertx-codegen</artifactId>
    <scope>provided</scope>
    <classifier>processor</classifier>
</dependency>
<dependency>
    <groupId>io.vertx</groupId>
    <artifactId>vertx-lang-js</artifactId>
    <scope>provided</scope>
</dependency>
----

<<<
=== [[section-4-a]] Set Up For Testing

Vert.x comes with a JUnit-compatible library for doing unit testing called `vertx-unit`. Personally,
I prefer BDD style tests, so for this workshop I will be demonstrating
http://spockframework.org/spock/docs/1.1/index.html[SpockFramework]. To use Spock, we will need to
add some additional dependencies to our POM:

.Adding Libraries For Spock Framework and Code Coverage
[source,xml,subs=attributes+]
----
<dependency>
    <groupId>org.codehaus.groovy</groupId>
    <artifactId>groovy-all</artifactId>
    <version>2.4.12</version>
    <scope>test</scope>
</dependency>
<dependency>
    <groupId>org.javassist</groupId>
    <artifactId>javassist</artifactId>
    <version>3.21.0-GA</version>
    <scope>test</scope>
</dependency>
<dependency>
    <groupId>org.spockframework</groupId>
    <artifactId>spock-core</artifactId>
    <version>1.1-groovy-2.4</version>
    <scope>test</scope>
</dependency>
<dependency>
    <groupId>net.bytebuddy</groupId>
    <artifactId>byte-buddy</artifactId>
    <version>1.7.5</version>
    <scope>test</scope>
</dependency>
<dependency> <!-- enables mocking of classes without default constructor -->
    <groupId>org.objenesis</groupId>
    <artifactId>objenesis</artifactId>
    <version>2.6</version>
    <scope>test</scope>
</dependency>
----

We will also need to add the GMavenPlus plugin and configure the Maven SureFire plugin to be able to
run the Spock tests:

.Add Maven Plugins For Spock Framework and Code Coverage
[source,xml,subs=attributes+]
----
<build>
    <plugins>
    ... SNIP ...
        <plugin>    <!-- Add support for compiling Groovy files -->
            <groupId>org.codehaus.gmavenplus</groupId>
            <artifactId>gmavenplus-plugin</artifactId>
            <version>1.5</version>
            <executions>
                <execution>
                    <goals>
                        <goal>addSources</goal>
                        <goal>addTestSources</goal>
                        <goal>generateStubs</goal>
                        <goal>compile</goal>
                        <goal>testGenerateStubs</goal>
                        <goal>testCompile</goal>
                        <goal>removeStubs</goal>
                        <goal>removeTestStubs</goal>
                    </goals>
                </execution>
            </executions>
        </plugin>
        <plugin> <!-- Configure the Maven SureFire to use Groovy Spec files for test -->
            <artifactId>maven-surefire-plugin</artifactId>
            <version>2.6</version>
            <configuration>
                <useFile>false</useFile>
                <includes>
                    <include>**/*Spec.groovy</include>
                </includes>
            </configuration>
        </plugin>
        <plugin> <!-- Configure JaCoCo to be able to extract code coverage information -->
            <groupId>org.jacoco</groupId>
            <artifactId>jacoco-maven-plugin</artifactId>
            <version>0.7.6.201602180812</version>
            <executions>
                <execution>
                    <id>jacoco-initialize</id>
                    <goals>
                        <goal>prepare-agent</goal>
                    </goals>
                </execution>
                <execution>
                    <id>jacoco-site</id>
                    <phase>test</phase>
                    <goals>
                        <goal>report</goal>
                    </goals>
                </execution>
            </executions>
        </plugin>
    ... SNIP ...
    </plugins>
</build>
----

<<<
=== [[section-4-b]] Basic Vert.x Concepts

The https://vertx.io/docs/vertx-core/java/[Vert.x Core Documentation] is a really great reference to some of the basic
concepts in Vert.x. We'll cover a few of these things here, but please feel free to go to the official docs for more
in-depth information.

Vert.x implements a *fluent* SPI. This means that for most Vert.x components, you can chain calls together in a nicely
readable manner.

[source,java,subs=attributes+]
----
vertx.eventBus()
     .consumer("some-address")
     .toObservable()
     .doOnError(this::errorHandler)
     .subscribe(this::messageHandler);
----

Another core concept of Vert.x is that everything which is done in a Verticle should be done in a non-blocking way.
To support this, Vert.x provides non-blocking implementations of many common functionalities such as:

* File I/O
* Network I/O
* Database Access
* Message Queues
* HTTP Clients/Servers
* Authentication/Authorization/Audit (AAA)
* Metrics

==== Verticles
From the new project we generated via Maven, we can see that a class called `MainVerticle` was created.
https://vertx.io/docs/vertx-core/java/#_verticles[Verticles] are the basic unit of an application in Vert.x. By default,
Verticles are run single-threaded on an event loop (Reactor Pattern). The one difference between this and other Reactor
Pattern implementations you may have seen before is that Vert.x runs MULTIPLE event loops in parallel, calling it
https://vertx.io/docs/vertx-core/java/#_reactor_and_multi_reactor[Multi-Reactor].

The basic contents of a Vertical are a class definition and a `start` method, as shown here:

[source,java,subs=attributes+]
----
package com.redhat.qcon;

import io.vertx.core.AbstractVerticle;
import io.vertx.core.Future;

public class MainVerticle extends AbstractVerticle {

    @Override
    public void start(Future<Void> startFuture) {
        startFuture.complete(); // Called once the Vertical is ready
    }
}
----

==== Non-Blocking
Because Vert.x uses event loops for Verticles, we must always ensure that we do not call blocking code and thus block
the event loop. Since Vert.x does not have non-blocking APIs for every situation, it provides a method of
implementing traditional blocking Java code using the `vertx.executeBlocking` method. For example, if we wanted to make a
call via http://www.oracle.com/technetwork/java/jndi/index.html[JNDI] to look up something in an LDAP directory, we
might do something like:

[source,java,subs=attributes+]
----
vertx.executeBlocking(future -> {
    // Make our JNDI calls here!
    future.complete(result);
}, result -> {
    // Handle the results of the blocking operation once it completes.
});
----

==== [[section-4-b-eventbus]] Event Bus
The final concept we should introduce for Vert.x is the Event Bus. Since all of the Verticles are implemented to
run single-threaded and potentially across multiple threads/cores in parallel, we need a safe way to share data which
will not cause race conditions or concurrency problems. To facilitate this, Vert.x has an Event Bus through which we
can send/receive messages between Verticles. A simple example of using the event bus might look like:

[source,java,subs=attributes+]
----
// Create a consumer and reply when we get PING messages
vertx.eventBus()
    .consumer("ping-timer")
    .toFlowable()
    .doOnEach(m -> System.out.println(m.getValue().body()))
    .subscribe(m -> m.reply(new JsonObject().put("action", "PONG")));

// Set a period timer to send a "PING" message every 300 milliseconds
vertx.timerStream(300)
    .toObservable()
    .map(t -> new JsonObject().put("action", "PING"))
    .subscribe(ping -> vertx.eventBus()
            .rxSend("ping-timer", ping)
            .subscribe(m -> System.out.println(m.body())));
----

<<<
=== [[section-4-c]] Implement Kubernetes Config
Following one of the tenets of https://12factor.net/config[12 Factor Applications], we will want to store our
application's configuration in the deployment environment instead of in our code. Vert.x makes this somewhat painless
by providing a comprehensive set of APIs for loading the application's configuration. In our case, since we are
deploying to Kubernetes, we will use Kubernetes ConfigMaps for our configuration.

Another best practice is that we should practice "test first" development. To further that concept, let's start
by writing a failing test for the feature we intent to implement.

.src/test/groovy/com/redhat/qcon/MainVerticleSpec.groovy
[source,groovy,subs=attributes+]
----
package com.redhat.qcon

import io.vertx.core.Future
import io.vertx.core.Vertx
import spock.lang.Specification
import spock.util.concurrent.AsyncConditions

class MainVerticleSpec extends Specification {

    def 'Test Vert.x configuration loading'() {
        given: 'An instance of Vert.x'                          {conum-guard-groovy} <1>
            def vertx = Vertx.vertx()
        and: 'An instance of a Vert.x Future'                   {conum-guard-groovy} <2>
            def fut = Future.future()
        and: '''An instance of Spock's AsyncConditions'''       {conum-guard-groovy} <3>
            def async = new AsyncConditions(1)

        when: 'We attempt to deploy the main Verticle'          {conum-guard-groovy} <4>
            vertx.deployVerticle(new MainVerticle(), fut.completer())

        then: 'Expect that the correct configuration is found and loaded'
            fut.setHandler({ res ->
                async.evaluate {                                {conum-guard-groovy} <5>
                    res.succeeded()                             {conum-guard-groovy} <6>
                    def config = vertx.getOrCreateContext().config()
                    config.hasProperty('noun')                  {conum-guard-groovy} <7>
                    config.hasProperty('adjective')             {conum-guard-groovy} <8>
                    config.hasProperty('http')                  {conum-guard-groovy} <9>
                }
            })

        cleanup: 'Await the async operations'                   {conum-guard-groovy} <10>
            async.await(10)
    }
}
----
<1> Set our starting conditions. In this case, we need a running Vert.x instance
<2> Using the `and` block, we can specify additional `given`, `when`, or `then` conditions
<3> Use the `when` block to call the code under test
<4> The `AsyncConditions` class is provided by Spock to allow us to check for one or more asynchronous events
<5> Use the `async.evaluate` to tell Spock that we are waiting for an asynchronous operation
<6> Check to ensure that the future completed successfully
<7> Check to ensure that the config contains a `noun` property
<8> Check to ensure that the config contains a `adjective` property
<9> Check to ensure that the config contains a `http` property
<10> Tell Spock to wait `10` seconds for the async operations to complete

Spock tests are written using a format known as Gherkin. Gherkin formats tests as given-when-then. Spock also has
a format for writing data-driven tests which we will use and explain later.

Now that we have written our test, here's how I would implement the feature code.

.Implementing Kubernetes ConfigMap Support
[source,java,subs=attributes+]
----
package com.redhat.qcon;

import io.reactivex.Single;
import io.vertx.config.ConfigRetrieverOptions;
import io.vertx.config.ConfigStoreOptions;
import io.vertx.core.Future;
import io.vertx.core.json.JsonObject;
import io.vertx.reactivex.config.ConfigRetriever;
import io.vertx.reactivex.core.AbstractVerticle;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

public class MainVerticle extends AbstractVerticle {

    private static final Logger LOG = LoggerFactory.getLogger(MainVerticle.class);

    Single<JsonObject> initConfigRetriever() {                                  {conum-guard-groovy} <1>
        // Load the default configuration from the classpath
        LOG.info("Configuration store loading.");
        ConfigStoreOptions defaultOpts = new ConfigStoreOptions()               {conum-guard-groovy} <2>
                .setType("file")
                .setFormat("json")
                .setConfig(new JsonObject().put("path", "insult_default_config.json"));

        // Load container specific configuration from a specific file path inside of the
        // container
        ConfigStoreOptions localConfig = new ConfigStoreOptions()               {conum-guard-groovy} <3>
                .setType("file")
                .setFormat("json")
                .setConfig(new JsonObject().put("path", "/opt/docker_config.json"))
                .setOptional(true);

        // When running inside of Kubernetes, configure the application to also load from
        // a ConfigMap
        ConfigStoreOptions confOpts = new ConfigStoreOptions()                  {conum-guard-groovy} <4>
                .setType("configmap")
                .setConfig(new JsonObject()
                        .put("name", "insult-config")
                        .put("optional", true)
                );

        // Add the default and container config options into the ConfigRetriever
        ConfigRetrieverOptions retrieverOptions = new ConfigRetrieverOptions()  {conum-guard-groovy} <5>
                .addStore(defaultOpts)
                .addStore(localConfig)
                .addStore(confOpts);

        // Create the ConfigRetriever and return the Maybe when complete
        return ConfigRetriever.create(vertx, retrieverOptions).rxGetConfig();   {conum-guard-groovy} <6>
    }

    @Override
    public void start(Future<Void> startFuture) {

        initConfigRetriever()                                                   {conum-guard-groovy} <7>
                .doOnError(startFuture::fail)                                   {conum-guard-groovy} <8>
                .subscribe(c -> {
                    LOG.info(c.encodePrettily());
                    context.config().mergeIn(c);                                {conum-guard-groovy} <9>
                    startFuture.complete();                                     {conum-guard-groovy} <10>
                });
    }
}
----
<1> Define a new method which returns a `Single` with the configuration
<2> Create an instance of `ConfigStoreOptions` to load the default config from the classpath
<3> Create an instance of `ConfigStoreOptions` to load configuration data from inside a Docker container
<4> Create an instance of `ConfigStoreOptions` to load configuration data from Kubernetes ConfigMaps
<5> Attach the `ConfigStoreOptions` to the `ConfigRetrieverOptions`
<6> Return the RxJava2 `Single` which may be completed at a later time
<7> From inside of the `start` method, call `initConfigRetriever`
<8> Set an error handler for the `Single` which will fail the Verticle deployment when an error is encountered
<9> Merge the loaded configuration into the global Vert.x configuration
<10> Complete the `startFuture` successfully

This example replaces the generic Verticle type with one which has been refactored to use
Reactive Extensions. Most of the rest of this Workshop with rely on using ReactiveX for
our Vert.x code.

[IMPORTANT]
====
When using the Vert.x ConfigStoreOptions, remember that the order in which ConfigStoreOptions are added
is significant. Items added later will override values from items which were loaded earlier. For example, if the
default config sets `noun.host = 'localhost'`, but the Kubernetes ConfigMap sets `noun.host = '192.168.1.10'`,
the ConfigMap value will take precedence.
====

[NOTE]
====
The single Spock test which we wrote allows us to achieve 100% line AND branch coverage without using ANY dependency
injection because it is a limited form of integration test. Admittedly, the test does not test the Kubernetes ConfigMap
unless it is run inside of Kubernetes/OpenShift, but that would violate the rule of *_Don't test the framework, only test
your code_*. Keep in mind that *I am NOT advocating for 100% coverage*, as that leads to spending a lot of
time and resources for little gain. You should, however, aim to cover all critical paths in your tests.
====

<<<
=== [[section-4-d]] Configure Vert.x Clustering With Infinispan/JGroups
A really impressive feature we can use in Vert.x is it's low-level support for clustering and distributed processing
using the Event Bus. Vert.x supports a few different cluster manager implementations like
https://vertx.io/docs/vertx-hazelcast/java[Hazelcast], https://vertx.io/docs/vertx-infinispan/java[Infinispan],
https://vertx.io/docs/vertx-ignite/java[Apache Ignite], and https://vertx.io/docs/vertx-zookeeper/java[Apache Zookeeper].
Each of these has different use cases, but all accomplish the same goal: Vert.x instances can discover one-another and
then form a mesh-network over the event bus. Once a cluster is formed, the features available include:

* Discovery and group membership of Vert.x nodes in a cluster
* Maintaining cluster wide topic subscriber lists (so we know which nodes are interested in which event bus addresses)
* Distributed Map support
* Distributed Locks
* Distributed Counters

These features are used in some of Vert.x's other features for things like distributed session management for web
applications.


==== [[section-4-d-1]] Add Clustering Dependencies
For this workshop, since we are using Kubernetes, we will use the Infinispan Cluster Manager by adding the following
dependency

.pom.xml Snippet
[source,xml]
----
    <dependencies>
        <dependency>
            <groupId>io.vertx</groupId>
            <artifactId>vertx-infinispan</artifactId>
        </dependency>
        <dependency>
          <groupId>org.infinispan</groupId>
          <artifactId>infinispan-cloud</artifactId>
          <version>9.1.3.Final</version>
        </dependency>
        <dependency>
          <groupId>org.jgroups.kubernetes</groupId>
          <artifactId>jgroups-kubernetes</artifactId>
          <version>1.0.3.Final</version>
        </dependency>
        ...SNIP...
----


When running locally, we can just add `--cluster` to the execution of the fat-jar and Infinispan+JGroups will automatically
discover other Vert.x nodes on the same network segment via Multicast DNS (MCAST_PING).

==== [[section-4-d-2]] Clustering Inside Kubernetes/OpenShift
When running inside of Kubernetes or OpenShift, we change the config with the system property
`-Dvertx.jgroups.config=default-configs/default-jgroups-kubernetes.xml`.

In our deployment environment, we need to set the `default` service account to have `view` role inside of the
namespace and also set the `KUBERNETES_NAMESPACE` environment variable. With these changes in place, the Vert.x Pods
will automatically discover one another using the Kubernetes API.


==== [[section-4-d-3]] Benefits Of Vert.x Clustering
This means that event bus messages can be sent and received across all Vert.x instances. This makes it possible to:

* Distribute capabilities to different microservices in a reactive manner
* Scale microservices independently
* Coordinate across microservices using distributed counters and locks
* Provide a simple API for service communications without the overhead of REST (see https://vertx.io/docs/vertx-service-proxy/java/[Service Proxies])

[NOTE]
====
If you are using an OpenShift cluster which has Multi-tenant networking and UDP multicast enabled, you can skip the
Kubernetes specific config as the cluster will allow Multicast DNS discovery inside of each Namespace just fine.
====

<<<
=== [[section-4-e]] Implement a new https://vertx.io/docs/vertx-service-proxy/java/[Service Proxy]
Vert.x provides a facility to make it easier to consume/produce messages on the Event Bus. In the first
<<#section-4-b-eventbus,example>> of sending and receiving on the event bus, we used a producer and a consumer based on
rx-java2. Setting each of these various endpoints can become tedious and does not provide the best developer
experience. Instead, we can use Vert.x Service Proxies to provide an easier way to implement business logic
and then expose that business logic on the event bus in a more consumable manner. These Service Proxy implementations
can also be used in a clustered Vert.x environment to allow us to have simple interactions between services across
multiple microservices. For our workshop, we will be integrating with a few other microservices which provide the Nouns
and Adjectives for our insults. The Noun service is implemented in NodeJS, while the Adjective service is implemented
using Spring Boot.

==== [[section-4-e-1]] Prepare For The Code Generator

In order for the Vert.x code generation to work, we need to annotate the package which will contain the code to be
processed. We do this by creating a `package-info.java` file. You should place this file deep enough in the heirarchy
that will prevent most of the code from being considered, but high enough that you can process all required code:

.src/main/java/com/redhat/qcon/services/package-info.java
[source,java,subs=attributes+]
----
@ModuleGen(name = "insult", groupPackage = "com.redhat.qcon.insult.services")
package com.redhat.qcon.insult.services;

import io.vertx.codegen.annotations.ModuleGen;
----

==== [[section-4-e-2]] The Interface
All service proxies start with an Interface definition which looks something like this:

.src/main/java/com/redhat/qcon/services/insult/InsultService.java
[source,java,subs=attributes+]
----
package com.redhat.qcon.insult.services.insult;

import io.vertx.codegen.annotations.Fluent;
import io.vertx.codegen.annotations.ProxyGen;
import io.vertx.codegen.annotations.VertxGen;
import io.vertx.core.AsyncResult;
import io.vertx.core.Handler;
import io.vertx.core.Vertx;
import io.vertx.core.json.JsonObject;

@ProxyGen
@VertxGen
public interface InsultService {

    static InsultService create(Vertx vertx) {
        return new InsultServiceImpl(vertx, vertx.getOrCreateContext().config());
    }

    static InsultService createProxy(Vertx vertx, String address) {
        return new InsultServiceVertxEBProxy(vertx, address);
    }

    // Business logic methods here!!

    /**
     * Retrieve an insult from the child services and build the insult payload
     * @param insultGetHandler A {@link Handler} callback for the results
     */
    void getREST(Handler<AsyncResult<JsonObject>> insultGetHandler);

    /**
     * Publish a "liked" insult to the Kafka queue to be distributed to all of the other
     * clusters
     * @param insult An insult made up of 2 adjectives and a noun
     * @param insultPublishHandler A {@link Handler} callback for the results
     */
    @Fluent
    InsultService publish(JsonObject insult, Handler<AsyncResult<Void>> insultPublishHandler);
}
----

All of the business logic methods return "void" or the can be fluent and return their service instance.
The two static methods at the beginning are boilerplate for Service Proxies. These methods are used
by the underlying runtime to provide a simple means of wiring up the service proxy.

[NOTE]
====
The business logic methods do not have an access modifier set (e.g. `public`/`private`/`protected`). This means that it
defaults to *_package private_*. By doing this, when we implement unit/BDD tests with Spock we can call those methods
directly in order to facilitate simplified testing.
====

==== [[section-4-e-3]] Test First Development

When we use the philosophy of _test first_ development, we expect to follow the pattern of:

* [big red]#RED#
* [big green]#GREEN#
* [big yellow]#REFACTOR#

This means that we write a test before we write any code and expect it to fail ([red]#red#). We then write code until
the test passes ([green]#green#). Finally, we plan for any refactoring and start the loop over again.

[NOTE]
====
Using a tool like https://infinitest.github.io/[Infinitest] can be VERY useful to improve your development iterations.
Infinitest _watches_ for changes in your source code and constantly re-runs the appropriate tests when a file changes.
====

Now that we have an interface, we need to create a series of tests for that code. As mentioned at the start, we will be
using http://spockframework.org/spock/docs/1.1/index.html[Spock Framework] in order to write BDD style _Specifications_.
Spock Specifications are quite easy to write and lend themselves to readability. We start off with a Groovy class which
extends `Specification`.

.src/test/groovy/com/redhat/qcon/services/insult/InsultServiceImplSpec.groovy
[source,java,subs=attributes+]
----
package com.redhat.qcon.insult.services.insult

import spock.lang.Specification

class InsultServiceImplSpec extends Specification {

}
----

That's the extend of the boilerplate required for writing tests. Spock also supports pre-operations like:

* `setup()` - A method run before EACH TEST
* `setupSpec()` - A method run before the entire test class
* `cleanup()` - A method run after EACH TEST
* `cleanupSpec()` - A method run after ALL of the tests in the class are complete

Any resources which you would want to re-use across tests will need to be defined at the class scope and annotated as
`@Shared`, otherwise Spock will prevent the tests from running. This is to ensure that you don't accidentally re-use
state without being explicit. `static final` field are acceptable too.

.src/test/groovy/com/redhat/qcon/services/insult/InsultServiceImplSpec.groovy
[source,java,subs=attributes+]
----
package com.redhat.qcon.insult.services.insult

import spock.lang.Specification
import io.specto.hoverfly.junit.core.Hoverfly
import io.specto.hoverfly.junit.core.SimulationSource
import spock.lang.Shared
import io.vertx.core.json.JsonObject
import io.vertx.core.Vertx

class InsultServiceImplSpec extends Specification {

    @Shared
    Hoverfly hoverfly

    @Shared
    Vertx vertx

    @Shared
    JsonObject proxyOptions

    static final String NOUN_RESPONSE_BODY_ONE =
                                new JsonObject().put('noun', 'noun').encodePrettily()
    static final String ADJ_RESPONSE_BODY_ONE =
                                new JsonObject().put('adj', 'adjective').encodePrettily()
}
----

You will notice that we have defined a `Hoverfly` instance, and we will use this in our tests to simulate the dependent
services which this service will interact with. Hoverfly implements an HTTP proxy which can intercept _simulated_
interactions with an external service. We will use this to simulate both successful and failed responses from the
other microservices so that we can easily test in isolation.

To implement the simuations in Hoverfly, we use the
http://hoverfly.readthedocs.io/projects/hoverfly-java/en/latest/pages/corefunctionality/dsl.html[Hoverfly DSL] to
define a `SimulationSource`.

.src/test/groovy/com/redhat/qcon/services/insult/InsultServiceImplSpec.groovy
[source,java,subs=attributes+]
----
    // -- SNIP --

    static final String NOUN_RESPONSE_BODY_ONE =
                            new JsonObject().put('noun', 'noun').encodePrettily()
    static final String ADJ_RESPONSE_BODY_ONE =
                            new JsonObject().put('adj', 'adjective').encodePrettily()

    static final SimulationSource GET_RESPONSE_ONE = dsl(                       {conum-guard-groovy} <1>
            service('localhost')
                    .get("/api/v1/noun")
                    .willReturn(success(NOUN_RESPONSE_BODY_ONE,
                                        APPLICATION_JSON.toString())),
            service('localhost')
                    .get("/api/v1/adjective")
                    .willReturn(success(ADJ_RESPONSE_BODY_ONE,
                                        APPLICATION_JSON.toString())))

    static final SimulationSource GET_RESPONSE_TWO = dsl(                       {conum-guard-groovy} <2>
            service('localhost')
                    .get("/api/v1/noun")
                    .willReturn(serverError()))

    static final SimulationSource GET_RESPONSE_THREE = dsl(                     {conum-guard-groovy} <3>
            service('localhost')
                    .andDelay(10, TimeUnit.SECONDS).forAll(),
            service('localhost')
                    .get('/api/v1/noun')
                    .willReturn(success(NOUN_RESPONSE_BODY_ONE,
                                        APPLICATION_JSON.toString())),
            service('localhost')
                    .get("/api/v1/adjective")
                    .willReturn(success(ADJ_RESPONSE_BODY_ONE,
                                        APPLICATION_JSON.toString())))

    def setupSpec() {                                                           {conum-guard-groovy} <4>
        System.setProperty('org.slf4j.simpleLogger.defaultLogLevel', 'debug')
        def hoverflyConfig = localConfigs().proxyLocalHost().captureAllHeaders()
        hoverfly = new Hoverfly(hoverflyConfig, SIMULATE)
        hoverfly.start()
        proxyOptions = new JsonObject()
                .put('host', 'localhost')
                .put('port', hoverfly.hoverflyConfig.proxyPort)
                .put('type', 'HTTP')
        vertx = Vertx.vertx()                                                   {conum-guard-groovy} <5>
    }

    def setup() {
        hoverfly.resetJournal()                                                 {conum-guard-groovy} <6>
    }

    // -- SNIP --
----
<1> The first simulation is the happy path where a good response is send by both services
<2> The second simulation has the noun service return a 5XX error
<3> The third simulation returns a 2XX response, but after a delay (This will be used later to test circuit breakers)
<4> In the `setupSpec()` method, we instantiate the Hoverfly proxy service and extract the proxy settings
<5> Finally, we create a new `Vertx` instance within which we will run all of our specifications
<6> In the `setup()` method, we ensure that the state of Hoverfly is reset before each test specification

==== [[section-4-e-4]] Creating The Service Implementation

We can now create a class which implements our interface. We have left the service implementation class as a stub so
that we can delve deeper into HTTP clients in the next section.

.src/main/java/com/redhat/qcon/services/insult/InsultServiceImpl.java
[source,java,subs=attributes+]
----
package com.redhat.qcon.insult.services.insult;

import io.vertx.core.AsyncResult;
import io.vertx.core.Handler;
import io.vertx.core.json.JsonObject;
import io.vertx.reactivex.core.Vertx;
import static java.lang.String.format;

public class InsultServiceImpl implements InsultService {

    /**
     * Request adjectives and a noun from the other microservices
     * @param insultGetHandler A {@link Handler} callback for the results
     */
    @Override
    public void getREST(Handler<AsyncResult<JsonObject>> insultGetHandler) {
        throw new Exception("Not Implemented");
    }

    /**
     * The the {@link KafkaService} event bus proxy to make calls to the Kafka
     * microservice
     * @param insult An insult made up of 2 adjectives and a noun
     * @param handler A handler to be called
     */
    @Override
    public InsultService publish(JsonObject insult, Handler<AsyncResult<Void>> handler) {
        throw new Exception("Not Implemented");
    }
}
----

<<<
=== [[section-4-f]] Implement REST clients
Vert.x provides both a high-level and low-level method of interacting with HTTP servers. In the core Vert.x package,
there is `vertx.createHttpClient()`, and it allows for very customizable handling of making requests to HTTP servers.
For more simple interactions with HTTP servers, the Vert.x team provides the `vertx-web-client` library. For interacting
with the other microservices via REST, we will use the web client. The simple case of using the web client is
demonstrated below:

==== [[section-4-f-1]] Vert.x Web Client
.Web Client Example
[source,java,subs=attributes+]
----
WebClientOptions opts = new WebClientOptions()
                                .setLogActivity(true)
                                .setDefaultHost("localhost")
                                .setDefaultPort(8080)
                                .setProxyOptions(proxyOptions);
WebClient client = WebClient.create(vertx, opts);

client.get("/some/path")
        .timeout(3000)
        .rxSend()
        .map(resp -> {                        // Map 4XX and 5XX responses to Exceptions
            if (resp.statusCode()>=400) {
                throw new HttpResponseException(resp.statusCode(), resp.statusMessage());
            }
            return resp;
        })
        .map(HttpResponse::bodyAsJsonObject)
        .doOnError(e -> {
            // Handle exceptions
        })
        .subscribe(json -> {
            // Handle successful JSON response body
        });
----

This is pretty concise code, but it is not terribly readable. The in-line lambdas are also difficult to test in
isolation. Instead, we can extract those into void stateless methods which are simple to test and read.

.Web Client Example
[source,java,subs=attributes+]
----
private HttpResponse<Buffer> mapErrors(HttpResponse<Buffer> resp)
                                                        throws HttpResponseException {
    // Map 4XX and 5XX responses to Exceptions
    if (resp.statusCode()>=400) {
        throw new HttpResponseException(resp.statusCode(), resp.statusMessage());
    }
    return resp;
}

private void example(Future<JsonObject> httpResponse) {
    WebClientOptions opts = new WebClientOptions()
                                    .setLogActivity(true)
                                    .setDefaultHost("localhost")
                                    .setDefaultPort(8080)
                                    .setProxyOptions(proxyOptions);
    WebClient client = WebClient.create(vertx, opts);

    client.get("/some/path")
            .timeout(3000)
            .rxSend()
            .map(this::mapErrors)
            .map(HttpResponse::bodyAsJsonObject)
            .doOnError(httpResponse::fail)
            .subscribe(httpResponse::complete);
}
----

This code is simple to test and easier to read. As we go forward, this is the pattern I will advocate.

==== [[section-4-f-2]] Implementing the Insult Service Using Web Client
Now, let's implement some methods so that we can make requests to our associated microservices and retrieve the results.

.src/main/java/com/redhat/qcon/services/insult/InsultServiceImpl.java
[source,java,subs=attributes+]
----
package com.redhat.qcon.insult.services.insult;

import io.vertx.core.AsyncResult;
import io.vertx.core.Handler;
import io.vertx.core.json.JsonObject;
import io.vertx.reactivex.core.Vertx;
import static java.lang.String.format;
import io.vertx.reactivex.core.Future;

public class InsultServiceImpl implements InsultService {

    Vertx vertx;
    WebClient nounClient, adjClient;

    /**
     * Default constructor
     * @param vertx The Vert.x instance to be used
     * @param config The {@link JsonObject} configuration for this service
     */
    public InsultServiceImpl(io.vertx.core.Vertx vertx, JsonObject config) {

        kafka = KafkaService.createProxy(Vertx.newInstance(vertx), "kafka.service");

        JsonObject nounConfig = config.getJsonObject("noun");
        JsonObject adjConfig = config.getJsonObject("adjective");
        this.vertx = Vertx.newInstance(vertx);
        WebClientOptions nounClientOpts = new WebClientOptions(nounConfig)
                .setLogActivity(true);
        WebClientOptions adjClientOpts = new WebClientOptions(adjConfig)
                .setLogActivity(true);
        nounClient = WebClient.create(this.vertx, nounClientOpts);
        adjClient = WebClient.create(this.vertx, adjClientOpts);
    }

    /**
     * Request adjectives and a noun from the other microservices
     * @param insultGetHandler A {@link Handler} callback for the results
     */
    @Override
    public void getREST(Handler<AsyncResult<JsonObject>> insultGetHandler) {
        throw new Exception("Not Implemented");
    }

    /**
     * The the {@link KafkaService} event bus proxy to make calls to the
     * Kafka microservice
     * @param insult An insult made up of 2 adjectives and a noun
     * @param handler A handler to be called
     */
    @Override
    public InsultService publish(JsonObject insult, Handler<AsyncResult<Void>> handler) {
        throw new Exception("Not Implemented");
    }

    /**
     * Maps HTTP error status codes to exceptions to interrupt the RxJava stream
     * processing and trigger an error handler
     * @param r The {@link HttpResponse} to be checked
     * @return The same as the input if the response code is 2XX
     * @throws Exception If the {@link HttpResponse} code is 4XX or 5XX
     */
    private static final HttpResponse<Buffer> mapStatusToError(HttpResponse<Buffer> r)
                                                                        throws Exception {
        if (r.statusCode()>=400) {
            throw new Exception(format("%d: %s\n%s", r.statusCode(),
                                r.statusMessage(), r.bodyAsString()));
        } else {
            return r;
        }
    }

    /**
     * Requests a noun from the appropriate microservice and returns a future with the
     * result
     * @return A {@link Future} of type {@link JsonObject} which will contain a noun on
     *         success
     */
    Future<JsonObject> getNoun() {
        Future<JsonObject> fut = Future.future();
        nounClient.get("/api/v1/noun")
                .timeout(3000)
                .rxSend()
                .map(InsultServiceImpl::mapStatusToError)
                .map(HttpResponse::bodyAsJsonObject)
                .doOnError(fut::fail)
                .subscribe(fut::complete);
        return fut;
    }

    /**
     * Requests an adjective from the appropriate microservice and returns a future with
     * the result
     * @return A {@link Future} of type {@link JsonObject} which will contain an adjective
     *         on success
     */
    Future<JsonObject> getAdjective() {
        Future<JsonObject> fut = Future.future();
        adjClient.get("/api/v1/adjective")
                .timeout(3000)
                .rxSend()
                .map(InsultServiceImpl::mapStatusToError)
                .map(HttpResponse::bodyAsJsonObject)
                .doOnError(fut::fail)
                .subscribe(fut::complete);
        return fut;
    }
}
----

We have defined some new methods which allow us to make HTTP requests and return `Future`s for asynchronous interaction.
These futures can then be composed in another method:

.src/main/java/com/redhat/qcon/services/insult/InsultServiceImpl.java
[source,java,subs=attributes+]
----
    // -- SNIP --

    /**
     * When the {@link CompositeFuture} is failed, throws an exception in order to
     * interrups the RxJava stream processing
     * @param res The {@link CompositeFuture} to be processed
     * @return Same as the input as long as the {@link CompositeFuture} was succeeded
     * @throws Exception If the {@link CompositeFuture} is failed
     */
    private static final CompositeFuture mapResultToError(CompositeFuture res)
                                                                    throws Exception {
        if (res.succeeded()) {
            return res;
        }
        throw new Exception(res.cause());
    }

    /**
     * Take results of {@link CompositeFuture} and return a composed {@link JsonObject}
     * containing the insult components
     * @param cf An instance of {@link CompositeFuture} which MUST be succeeded,
     *           otherwise it would have been filtered
     * @return A {@link JsonObject} containing a noun and an array of adjectives.
     */
    private static AsyncResult<JsonObject> buildInsult(CompositeFuture cf) {
        JsonObject insult = new JsonObject();
        JsonArray adjectives = new JsonArray();

        // Because there is no garanteed order of the returned futures, we need to parse
        the results
        for (int i=0; i<=cf.size(); i++) {
            JsonObject item = cf.resultAt(i);
            if (item.containsKey("adjective")) {
                adjectives.add(item.getString("adjective"));
            } else {
                insult.put("noun", item.getString("noun"));
            }
        }
        insult.put("adjectives", adjectives);

        return Future.succeededFuture(insult);
    }

    /**
     * Request adjectives and a noun from the other microservices
     * @param insultGetHandler A {@link Handler} callback for the results
     */
    @Override
    public void getREST(Handler<AsyncResult<JsonObject>> insultGetHandler) {
        // Request 2 adjectives and a noun in parallel, then handle the results
        CompositeFuture.all(getNoun(), getAdjective(), getAdjective())
                .rxSetHandler()
                .map(InsultServiceImpl::mapResultToError)   {conum-guard-groovy} <1>
                .map(InsultServiceImpl::buildInsult)        {conum-guard-groovy} <2>
                .onErrorReturn(Future::failedFuture)        {conum-guard-groovy} <3>
                .subscribe(insultGetHandler::handle);       {conum-guard-groovy} <4>
    }

    -- SNIP --
----
<1> Map errors to an exception
<2> Combine the 3 results into a single JSON object
<3> When an exception happens, map it to a failed future
<4> Map successful JSON to a succeeded future

`CompositeFuture.all(...)` tells Vert.x to run ALL of the specified methods and return when ANY of them fails or ALL
of them succeed. All of the methods are run non-blocking and potentially in parallel. In this case, we request 2
adjectives and a noun. We then pipe the the result through a handler which combines the 3 successful results into a
single `JsonObject`.

==== [[section-4-f-3]] Consuming A Service Proxy API From Another Vert.x Service

There is a third microservice implemented for you which we will need to interact with.
This service is implemented in Vert.x and uses Service Proxies. Since it is implemented
with Service Proxies, we can consume that service using the Service Proxy client which
is generated for us by Vert.x's Code Generation.

<<<
First, add the library for the service proxy client:

.pom.xml
[source,xml,subs=attributes+]
----
        <!-- SNIP -->
        <dependency>
            <groupId>com.redhat.qcon</groupId>
            <artifactId>kafka-service</artifactId>
            <version>1.0.0-SNAPSHOT</version>
        </dependency>
        <!-- SNIP -->
----

Next, we can create an instance of the Service Proxy from our application.

[source,java,subs=attributes+]
----
public class InsultServiceImpl implements InsultService {

    Vertx vertx;
    WebClient nounClient, adjClient;
    KafkaService kafka;

    /**
     * Default constructor
     * @param vertx The Vert.x instance to be used
     * @param config The {@link JsonObject} configuration for this service
     */
    public InsultServiceImpl(io.vertx.core.Vertx vertx, JsonObject config) {

        kafka = KafkaService
                    .createProxy(Vertx.newInstance(vertx), "kafka.service");    {conum-guard-groovy} <1>

        JsonObject nounConfig = config.getJsonObject("noun");
        JsonObject adjConfig = config.getJsonObject("adjective");
        this.vertx = Vertx.newInstance(vertx);
        WebClientOptions nounClientOpts = new WebClientOptions(nounConfig)
                .setLogActivity(true);
        WebClientOptions adjClientOpts = new WebClientOptions(adjConfig)
                .setLogActivity(true);
        nounClient = WebClient.create(this.vertx, nounClientOpts);
        adjClient = WebClient.create(this.vertx, adjClientOpts);
    }


    /**
     * Use the {@link KafkaService} event bus proxy to make calls to the
     * Kafka microservice
     * @param insult An insult made up of 2 adjectives and a noun
     * @param handler A handler to be called
     */
    @Override
    public InsultService publish(JsonObject insult, Handler<AsyncResult<Void>> handler) {
        Future<Void> fut = Future.future();                                     {conum-guard-groovy} <2>
        handler.handle(fut);                                                    {conum-guard-groovy} <3>
        kafka.rxPublish(insult)
                .toObservable()
                .doOnError(fut::fail)                                           {conum-guard-groovy} <4>
                .subscribe(v -> fut.complete());                                {conum-guard-groovy} <5>
        return this;
    }

    // -- SNIP --
----
<1> Create an instance of the proxy at the class scope (See note below)
<2> Create a Future with which to complete the handler
<3> Set the handler to use the Future
<4> Set the Rx error handler to fail the Future on error
<5> Set the completion of the Rx stream to complete the Future

[IMPORTANT]
====
When creating an instance of a Service Proxy client, you MUST ensure that the address
on the event bus matches the address on the service which binds that address. If the
addresses do not match, you will be sending messages into an unused message queue.
====

<<<
=== Implement REST API
==== TODO: Using OpenAPI 3 Spec file to create REST API in Vert.x

